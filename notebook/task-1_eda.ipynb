{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f26da3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_21968\\716076896.py:30: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(tickers, start=start_date, end=end_date)['Adj Close']\n",
      "[*********************100%***********************]  3 of 3 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for TSLA, BND, SPY from 2015-07-01 to 2025-07-31...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Adj Close'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Kifiya AI Master Training Program 5 6 &7\\week-11\\Time-Series-Forecasting-Portfolio-Optimization\\.desvenv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3811\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'Adj Close'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 30\u001b[39m\n\u001b[32m     27\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFetching data for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m.join(tickers)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstart_date\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mend_date\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     28\u001b[39m \u001b[38;5;66;03m# Download historical data from Yahoo Finance.\u001b[39;00m\n\u001b[32m     29\u001b[39m \u001b[38;5;66;03m# We use 'Adj Close' as it accounts for dividends and stock splits.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m data = \u001b[43myf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdownload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtickers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstart_date\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[43m=\u001b[49m\u001b[43mend_date\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mAdj Close\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mData fetching complete.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     32\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m-\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m50\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Kifiya AI Master Training Program 5 6 &7\\week-11\\Time-Series-Forecasting-Portfolio-Optimization\\.desvenv\\Lib\\site-packages\\pandas\\core\\frame.py:4106\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4104\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_single_key:\n\u001b[32m   4105\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m4106\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_getitem_multilevel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4107\u001b[39m     indexer = \u001b[38;5;28mself\u001b[39m.columns.get_loc(key)\n\u001b[32m   4108\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Kifiya AI Master Training Program 5 6 &7\\week-11\\Time-Series-Forecasting-Portfolio-Optimization\\.desvenv\\Lib\\site-packages\\pandas\\core\\frame.py:4164\u001b[39m, in \u001b[36mDataFrame._getitem_multilevel\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4162\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_getitem_multilevel\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[32m   4163\u001b[39m     \u001b[38;5;66;03m# self.columns is a MultiIndex\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m4164\u001b[39m     loc = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4165\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(loc, (\u001b[38;5;28mslice\u001b[39m, np.ndarray)):\n\u001b[32m   4166\u001b[39m         new_columns = \u001b[38;5;28mself\u001b[39m.columns[loc]\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Kifiya AI Master Training Program 5 6 &7\\week-11\\Time-Series-Forecasting-Portfolio-Optimization\\.desvenv\\Lib\\site-packages\\pandas\\core\\indexes\\multi.py:3059\u001b[39m, in \u001b[36mMultiIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3056\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m mask\n\u001b[32m   3058\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m3059\u001b[39m     loc = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_level_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   3060\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _maybe_to_slice(loc)\n\u001b[32m   3062\u001b[39m keylen = \u001b[38;5;28mlen\u001b[39m(key)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Kifiya AI Master Training Program 5 6 &7\\week-11\\Time-Series-Forecasting-Portfolio-Optimization\\.desvenv\\Lib\\site-packages\\pandas\\core\\indexes\\multi.py:3410\u001b[39m, in \u001b[36mMultiIndex._get_level_indexer\u001b[39m\u001b[34m(self, key, level, indexer)\u001b[39m\n\u001b[32m   3407\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mslice\u001b[39m(i, j, step)\n\u001b[32m   3409\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3410\u001b[39m     idx = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_loc_single_level_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlevel_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3412\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m level > \u001b[32m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lexsort_depth == \u001b[32m0\u001b[39m:\n\u001b[32m   3413\u001b[39m         \u001b[38;5;66;03m# Desired level is not sorted\u001b[39;00m\n\u001b[32m   3414\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(idx, \u001b[38;5;28mslice\u001b[39m):\n\u001b[32m   3415\u001b[39m             \u001b[38;5;66;03m# test_get_loc_partial_timestamp_multiindex\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Kifiya AI Master Training Program 5 6 &7\\week-11\\Time-Series-Forecasting-Portfolio-Optimization\\.desvenv\\Lib\\site-packages\\pandas\\core\\indexes\\multi.py:2999\u001b[39m, in \u001b[36mMultiIndex._get_loc_single_level_index\u001b[39m\u001b[34m(self, level_index, key)\u001b[39m\n\u001b[32m   2997\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m -\u001b[32m1\u001b[39m\n\u001b[32m   2998\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2999\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlevel_index\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Kifiya AI Master Training Program 5 6 &7\\week-11\\Time-Series-Forecasting-Portfolio-Optimization\\.desvenv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3819\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3814\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3815\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3816\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3817\u001b[39m     ):\n\u001b[32m   3818\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3819\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3820\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3821\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3822\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3823\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3824\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'Adj Close'"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Task 1: Data Preprocessing, EDA, and Risk Analysis\n",
    "#\n",
    "# This script covers the first major task of the \"Time Series Forecasting for\n",
    "# Portfolio Management Optimization\" challenge. It performs the following steps:\n",
    "# 1.  Fetches historical financial data for TSLA, BND, and SPY using the yfinance library.\n",
    "# 2.  Cleans the data by handling missing values.\n",
    "# 3.  Conducts Exploratory Data Analysis (EDA) to visualize trends and volatility.\n",
    "# 4.  Performs statistical tests for stationarity (Augmented Dickey-Fuller).\n",
    "# 5.  Calculates key risk metrics: Value at Risk (VaR) and the Sharpe Ratio.\n",
    "#\n",
    "\n",
    "# --- 0. Import Necessary Libraries ---\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "# --- 1. Data Extraction ---\n",
    "# Define the tickers and the date range for the data extraction.\n",
    "tickers = ['TSLA', 'BND', 'SPY']\n",
    "start_date = '2015-07-01'\n",
    "end_date = '2025-07-31'\n",
    "\n",
    "print(f\"Fetching data for {', '.join(tickers)} from {start_date} to {end_date}...\")\n",
    "# Download historical data from Yahoo Finance.\n",
    "# We use 'Adj Close' as it accounts for dividends and stock splits.\n",
    "data = yf.download(tickers, start=start_date, end=end_date)['Adj Close']\n",
    "print(\"Data fetching complete.\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "\n",
    "# --- 2. Data Cleaning and Understanding ---\n",
    "print(\"--- Data Cleaning and Understanding ---\")\n",
    "# Display the first few rows of the dataset\n",
    "print(\"First 5 rows of the data:\")\n",
    "print(data.head())\n",
    "print(\"\\n\")\n",
    "\n",
    "# Check basic statistics to understand the distribution of the data.\n",
    "print(\"Basic statistics of the data:\")\n",
    "print(data.describe())\n",
    "print(\"\\n\")\n",
    "\n",
    "# Check for missing values.\n",
    "print(\"Missing values in each column:\")\n",
    "print(data.isnull().sum())\n",
    "print(\"\\n\")\n",
    "\n",
    "# Handle missing values using forward fill, which is suitable for time series data.\n",
    "data.fillna(method='ffill', inplace=True)\n",
    "print(\"Missing values after forward fill:\")\n",
    "print(data.isnull().sum())\n",
    "print(\"-\" * 50)\n",
    "\n",
    "\n",
    "# --- 3. Exploratory Data Analysis (EDA) ---\n",
    "print(\"--- Performing Exploratory Data Analysis ---\")\n",
    "# Set plot style\n",
    "sns.set(style='whitegrid')\n",
    "\n",
    "# Visualize the closing prices over time\n",
    "plt.figure(figsize=(14, 7))\n",
    "for ticker in tickers:\n",
    "    plt.plot(data.index, data[ticker], label=ticker)\n",
    "plt.title('Adjusted Closing Prices (2015-2025)', fontsize=16)\n",
    "plt.xlabel('Date', fontsize=12)\n",
    "plt.ylabel('Adjusted Close Price (USD)', fontsize=12)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Calculate and plot the daily percentage change (daily returns)\n",
    "daily_returns = data.pct_change().dropna()\n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "for ticker in tickers:\n",
    "    plt.plot(daily_returns.index, daily_returns[ticker], label=ticker, alpha=0.7)\n",
    "plt.title('Daily Returns (Volatility)', fontsize=16)\n",
    "plt.xlabel('Date', fontsize=12)\n",
    "plt.ylabel('Percentage Change', fontsize=12)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Analyze volatility by calculating and plotting rolling means and standard deviations for TSLA\n",
    "rolling_window = 30\n",
    "tsla_rolling_mean = data['TSLA'].rolling(window=rolling_window).mean()\n",
    "tsla_rolling_std = data['TSLA'].rolling(window=rolling_window).std()\n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(data.index, data['TSLA'], label='TSLA Adj Close')\n",
    "plt.plot(tsla_rolling_mean.index, tsla_rolling_mean, label=f'{rolling_window}-Day Rolling Mean', color='orange')\n",
    "plt.plot(tsla_rolling_std.index, tsla_rolling_std, label=f'{rolling_window}-Day Rolling Std Dev', color='red')\n",
    "plt.title('TSLA Price with Rolling Mean and Standard Deviation', fontsize=16)\n",
    "plt.xlabel('Date', fontsize=12)\n",
    "plt.ylabel('Price (USD)', fontsize=12)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "print(\"EDA plots have been generated.\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "\n",
    "# --- 4. Seasonality and Trends (Stationarity Test) ---\n",
    "print(\"--- Performing Stationarity Tests (Augmented Dickey-Fuller) ---\")\n",
    "\n",
    "# Function to perform and interpret the ADF test\n",
    "def adf_test(series, name=''):\n",
    "    \"\"\"\n",
    "    Performs the Augmented Dickey-Fuller test for stationarity.\n",
    "    \"\"\"\n",
    "    print(f'ADF Test for: {name}')\n",
    "    result = adfuller(series.dropna())\n",
    "    print(f'ADF Statistic: {result[0]}')\n",
    "    print(f'p-value: {result[1]}')\n",
    "    print('Critical Values:')\n",
    "    for key, value in result[4].items():\n",
    "        print(f'\\t{key}: {value}')\n",
    "\n",
    "    if result[1] <= 0.05:\n",
    "        print(\"Conclusion: The series is likely stationary (reject the null hypothesis).\\n\")\n",
    "    else:\n",
    "        print(\"Conclusion: The series is likely non-stationary (fail to reject the null hypothesis).\\n\")\n",
    "\n",
    "# Perform ADF test on the closing prices (expected to be non-stationary)\n",
    "adf_test(data['TSLA'], 'TSLA Adjusted Close Price')\n",
    "\n",
    "# Perform ADF test on the daily returns (expected to be stationary)\n",
    "adf_test(daily_returns['TSLA'], 'TSLA Daily Returns')\n",
    "print(\"-\" * 50)\n",
    "\n",
    "\n",
    "# --- 5. Risk Metrics Calculation ---\n",
    "print(\"--- Calculating Foundational Risk Metrics for TSLA ---\")\n",
    "\n",
    "# Value at Risk (VaR) - 95% confidence\n",
    "# VaR at 95% confidence level means that 95% of the time, we expect the loss to be less than this value.\n",
    "confidence_level = 0.95\n",
    "var_95 = daily_returns['TSLA'].quantile(1 - confidence_level)\n",
    "print(f\"Value at Risk (VaR) at 95% confidence: {var_95:.2%}\")\n",
    "print(f\"This means that on any given day, there is a 5% chance that TSLA's stock will drop by {var_95:.2%} or more.\")\n",
    "print(\"\\n\")\n",
    "\n",
    "# Sharpe Ratio\n",
    "# The Sharpe ratio measures the performance of an investment compared to a risk-free asset, after adjusting for its risk.\n",
    "# Assuming a risk-free rate of 0 for simplicity.\n",
    "mean_return = daily_returns['TSLA'].mean()\n",
    "std_dev = daily_returns['TSLA'].std()\n",
    "# Annualize the Sharpe Ratio (assuming 252 trading days in a year)\n",
    "sharpe_ratio = (mean_return / std_dev) * np.sqrt(252)\n",
    "print(f\"Annualized Sharpe Ratio for TSLA: {sharpe_ratio:.2f}\")\n",
    "print(\"A higher Sharpe Ratio generally indicates better risk-adjusted return.\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "print(\"Task 1 script finished.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf591f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for TSLA, BND, SPY from 2015-07-01 to 2025-07-31...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_21968\\716076896.py:30: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(tickers, start=start_date, end=end_date)['Adj Close']\n",
      "[*********************100%***********************]  3 of 3 completed\n",
      "\n",
      "1 Failed download:\n",
      "['BND']: Timeout('Failed to perform, curl: (28) Operation timed out after 10010 milliseconds with 10404 bytes received. See https://curl.se/libcurl/c/libcurl-errors.html first for more details.')\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_21968\\716076896.py:53: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  data.fillna(method='ffill', inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data fetching complete.\n",
      "--------------------------------------------------\n",
      "--- Data Cleaning and Understanding ---\n",
      "First 5 rows of the data:\n",
      "Ticker      BND\n",
      "Date           \n",
      "2015-07-01  NaN\n",
      "2015-07-02  NaN\n",
      "2015-07-06  NaN\n",
      "2015-07-07  NaN\n",
      "2015-07-08  NaN\n",
      "\n",
      "\n",
      "Basic statistics of the data:\n",
      "Ticker  BND\n",
      "count   0.0\n",
      "mean    NaN\n",
      "std     NaN\n",
      "min     NaN\n",
      "25%     NaN\n",
      "50%     NaN\n",
      "75%     NaN\n",
      "max     NaN\n",
      "\n",
      "\n",
      "Missing values in each column:\n",
      "Ticker\n",
      "BND    2535\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "Missing values after forward fill:\n",
      "Ticker\n",
      "BND    2535\n",
      "dtype: int64\n",
      "--------------------------------------------------\n",
      "--- Performing Exploratory Data Analysis ---\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'TSLA'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Kifiya AI Master Training Program 5 6 &7\\week-11\\Time-Series-Forecasting-Portfolio-Optimization\\.desvenv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n",
      "\u001b[32m   3811\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\n",
      "\u001b[31mKeyError\u001b[39m: 'TSLA'\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 67\u001b[39m\n",
      "\u001b[32m     65\u001b[39m plt.figure(figsize=(\u001b[32m14\u001b[39m, \u001b[32m7\u001b[39m))\n",
      "\u001b[32m     66\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m ticker \u001b[38;5;129;01min\u001b[39;00m tickers:\n",
      "\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m     plt.plot(data.index, \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mticker\u001b[49m\u001b[43m]\u001b[49m, label=ticker)\n",
      "\u001b[32m     68\u001b[39m plt.title(\u001b[33m'\u001b[39m\u001b[33mAdjusted Closing Prices (2015-2025)\u001b[39m\u001b[33m'\u001b[39m, fontsize=\u001b[32m16\u001b[39m)\n",
      "\u001b[32m     69\u001b[39m plt.xlabel(\u001b[33m'\u001b[39m\u001b[33mDate\u001b[39m\u001b[33m'\u001b[39m, fontsize=\u001b[32m12\u001b[39m)\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Kifiya AI Master Training Program 5 6 &7\\week-11\\Time-Series-Forecasting-Portfolio-Optimization\\.desvenv\\Lib\\site-packages\\pandas\\core\\frame.py:4107\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n",
      "\u001b[32m   4105\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n",
      "\u001b[32m   4106\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n",
      "\u001b[32m-> \u001b[39m\u001b[32m4107\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[32m   4108\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n",
      "\u001b[32m   4109\u001b[39m     indexer = [indexer]\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Kifiya AI Master Training Program 5 6 &7\\week-11\\Time-Series-Forecasting-Portfolio-Optimization\\.desvenv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3819\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n",
      "\u001b[32m   3814\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n",
      "\u001b[32m   3815\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n",
      "\u001b[32m   3816\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n",
      "\u001b[32m   3817\u001b[39m     ):\n",
      "\u001b[32m   3818\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n",
      "\u001b[32m-> \u001b[39m\u001b[32m3819\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n",
      "\u001b[32m   3820\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n",
      "\u001b[32m   3821\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n",
      "\u001b[32m   3822\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n",
      "\u001b[32m   3823\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n",
      "\u001b[32m   3824\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\n",
      "\u001b[31mKeyError\u001b[39m: 'TSLA'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1400x700 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#\n",
    "# Task 1: Data Preprocessing, EDA, and Risk Analysis\n",
    "#\n",
    "# This script covers the first major task of the \"Time Series Forecasting for\n",
    "# Portfolio Management Optimization\" challenge. It performs the following steps:\n",
    "# 1.  Fetches historical financial data for TSLA, BND, and SPY using the yfinance library.\n",
    "# 2.  Cleans the data by handling missing values.\n",
    "# 3.  Conducts Exploratory Data Analysis (EDA) to visualize trends and volatility.\n",
    "# 4.  Performs statistical tests for stationarity (Augmented Dickey-Fuller).\n",
    "# 5.  Calculates key risk metrics: Value at Risk (VaR) and the Sharpe Ratio.\n",
    "#\n",
    "\n",
    "# --- 0. Import Necessary Libraries ---\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "# --- 1. Data Extraction ---\n",
    "# Define the tickers and the date range for the data extraction.\n",
    "tickers = ['TSLA', 'BND', 'SPY']\n",
    "start_date = '2015-07-01'\n",
    "end_date = '2025-07-31'\n",
    "\n",
    "print(f\"Fetching data for {', '.join(tickers)} from {start_date} to {end_date}...\")\n",
    "# Download historical data from Yahoo Finance.\n",
    "# We use 'Adj Close' as it accounts for dividends and stock splits.\n",
    "data = yf.download(tickers, start=start_date, end=end_date)['Adj Close']\n",
    "print(\"Data fetching complete.\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "\n",
    "# --- 2. Data Cleaning and Understanding ---\n",
    "print(\"--- Data Cleaning and Understanding ---\")\n",
    "# Display the first few rows of the dataset\n",
    "print(\"First 5 rows of the data:\")\n",
    "print(data.head())\n",
    "print(\"\\n\")\n",
    "\n",
    "# Check basic statistics to understand the distribution of the data.\n",
    "print(\"Basic statistics of the data:\")\n",
    "print(data.describe())\n",
    "print(\"\\n\")\n",
    "\n",
    "# Check for missing values.\n",
    "print(\"Missing values in each column:\")\n",
    "print(data.isnull().sum())\n",
    "print(\"\\n\")\n",
    "\n",
    "# Handle missing values using forward fill, which is suitable for time series data.\n",
    "data.fillna(method='ffill', inplace=True)\n",
    "print(\"Missing values after forward fill:\")\n",
    "print(data.isnull().sum())\n",
    "print(\"-\" * 50)\n",
    "\n",
    "\n",
    "# --- 3. Exploratory Data Analysis (EDA) ---\n",
    "print(\"--- Performing Exploratory Data Analysis ---\")\n",
    "# Set plot style\n",
    "sns.set(style='whitegrid')\n",
    "\n",
    "# Visualize the closing prices over time\n",
    "plt.figure(figsize=(14, 7))\n",
    "for ticker in tickers:\n",
    "    plt.plot(data.index, data[ticker], label=ticker)\n",
    "plt.title('Adjusted Closing Prices (2015-2025)', fontsize=16)\n",
    "plt.xlabel('Date', fontsize=12)\n",
    "plt.ylabel('Adjusted Close Price (USD)', fontsize=12)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Calculate and plot the daily percentage change (daily returns)\n",
    "daily_returns = data.pct_change().dropna()\n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "for ticker in tickers:\n",
    "    plt.plot(daily_returns.index, daily_returns[ticker], label=ticker, alpha=0.7)\n",
    "plt.title('Daily Returns (Volatility)', fontsize=16)\n",
    "plt.xlabel('Date', fontsize=12)\n",
    "plt.ylabel('Percentage Change', fontsize=12)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Analyze volatility by calculating and plotting rolling means and standard deviations for TSLA\n",
    "rolling_window = 30\n",
    "tsla_rolling_mean = data['TSLA'].rolling(window=rolling_window).mean()\n",
    "tsla_rolling_std = data['TSLA'].rolling(window=rolling_window).std()\n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(data.index, data['TSLA'], label='TSLA Adj Close')\n",
    "plt.plot(tsla_rolling_mean.index, tsla_rolling_mean, label=f'{rolling_window}-Day Rolling Mean', color='orange')\n",
    "plt.plot(tsla_rolling_std.index, tsla_rolling_std, label=f'{rolling_window}-Day Rolling Std Dev', color='red')\n",
    "plt.title('TSLA Price with Rolling Mean and Standard Deviation', fontsize=16)\n",
    "plt.xlabel('Date', fontsize=12)\n",
    "plt.ylabel('Price (USD)', fontsize=12)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "print(\"EDA plots have been generated.\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "\n",
    "# --- 4. Seasonality and Trends (Stationarity Test) ---\n",
    "print(\"--- Performing Stationarity Tests (Augmented Dickey-Fuller) ---\")\n",
    "\n",
    "# Function to perform and interpret the ADF test\n",
    "def adf_test(series, name=''):\n",
    "    \"\"\"\n",
    "    Performs the Augmented Dickey-Fuller test for stationarity.\n",
    "    \"\"\"\n",
    "    print(f'ADF Test for: {name}')\n",
    "    result = adfuller(series.dropna())\n",
    "    print(f'ADF Statistic: {result[0]}')\n",
    "    print(f'p-value: {result[1]}')\n",
    "    print('Critical Values:')\n",
    "    for key, value in result[4].items():\n",
    "        print(f'\\t{key}: {value}')\n",
    "\n",
    "    if result[1] <= 0.05:\n",
    "        print(\"Conclusion: The series is likely stationary (reject the null hypothesis).\\n\")\n",
    "    else:\n",
    "        print(\"Conclusion: The series is likely non-stationary (fail to reject the null hypothesis).\\n\")\n",
    "\n",
    "# Perform ADF test on the closing prices (expected to be non-stationary)\n",
    "adf_test(data['TSLA'], 'TSLA Adjusted Close Price')\n",
    "\n",
    "# Perform ADF test on the daily returns (expected to be stationary)\n",
    "adf_test(daily_returns['TSLA'], 'TSLA Daily Returns')\n",
    "print(\"-\" * 50)\n",
    "\n",
    "\n",
    "# --- 5. Risk Metrics Calculation ---\n",
    "print(\"--- Calculating Foundational Risk Metrics for TSLA ---\")\n",
    "\n",
    "# Value at Risk (VaR) - 95% confidence\n",
    "# VaR at 95% confidence level means that 95% of the time, we expect the loss to be less than this value.\n",
    "confidence_level = 0.95\n",
    "var_95 = daily_returns['TSLA'].quantile(1 - confidence_level)\n",
    "print(f\"Value at Risk (VaR) at 95% confidence: {var_95:.2%}\")\n",
    "print(f\"This means that on any given day, there is a 5% chance that TSLA's stock will drop by {var_95:.2%} or more.\")\n",
    "print(\"\\n\")\n",
    "\n",
    "# Sharpe Ratio\n",
    "# The Sharpe ratio measures the performance of an investment compared to a risk-free asset, after adjusting for its risk.\n",
    "# Assuming a risk-free rate of 0 for simplicity.\n",
    "mean_return = daily_returns['TSLA'].mean()\n",
    "std_dev = daily_returns['TSLA'].std()\n",
    "# Annualize the Sharpe Ratio (assuming 252 trading days in a year)\n",
    "sharpe_ratio = (mean_return / std_dev) * np.sqrt(252)\n",
    "print(f\"Annualized Sharpe Ratio for TSLA: {sharpe_ratio:.2f}\")\n",
    "print(\"A higher Sharpe Ratio generally indicates better risk-adjusted return.\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "print(\"Task 1 script finished.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb39ed87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for TSLA, BND, SPY from 2015-07-01 to 2025-07-31...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_21968\\716076896.py:30: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(tickers, start=start_date, end=end_date)['Adj Close']\n",
      "[*********************100%***********************]  3 of 3 completed\n",
      "\n",
      "1 Failed download:\n",
      "['BND']: Timeout('Failed to perform, curl: (28) Operation timed out after 10010 milliseconds with 10404 bytes received. See https://curl.se/libcurl/c/libcurl-errors.html first for more details.')\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_21968\\716076896.py:53: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  data.fillna(method='ffill', inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data fetching complete.\n",
      "--------------------------------------------------\n",
      "--- Data Cleaning and Understanding ---\n",
      "First 5 rows of the data:\n",
      "Ticker      BND\n",
      "Date           \n",
      "2015-07-01  NaN\n",
      "2015-07-02  NaN\n",
      "2015-07-06  NaN\n",
      "2015-07-07  NaN\n",
      "2015-07-08  NaN\n",
      "\n",
      "\n",
      "Basic statistics of the data:\n",
      "Ticker  BND\n",
      "count   0.0\n",
      "mean    NaN\n",
      "std     NaN\n",
      "min     NaN\n",
      "25%     NaN\n",
      "50%     NaN\n",
      "75%     NaN\n",
      "max     NaN\n",
      "\n",
      "\n",
      "Missing values in each column:\n",
      "Ticker\n",
      "BND    2535\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "Missing values after forward fill:\n",
      "Ticker\n",
      "BND    2535\n",
      "dtype: int64\n",
      "--------------------------------------------------\n",
      "--- Performing Exploratory Data Analysis ---\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'TSLA'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Kifiya AI Master Training Program 5 6 &7\\week-11\\Time-Series-Forecasting-Portfolio-Optimization\\.desvenv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n",
      "\u001b[32m   3811\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\n",
      "\u001b[31mKeyError\u001b[39m: 'TSLA'\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 67\u001b[39m\n",
      "\u001b[32m     65\u001b[39m plt.figure(figsize=(\u001b[32m14\u001b[39m, \u001b[32m7\u001b[39m))\n",
      "\u001b[32m     66\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m ticker \u001b[38;5;129;01min\u001b[39;00m tickers:\n",
      "\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m     plt.plot(data.index, \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mticker\u001b[49m\u001b[43m]\u001b[49m, label=ticker)\n",
      "\u001b[32m     68\u001b[39m plt.title(\u001b[33m'\u001b[39m\u001b[33mAdjusted Closing Prices (2015-2025)\u001b[39m\u001b[33m'\u001b[39m, fontsize=\u001b[32m16\u001b[39m)\n",
      "\u001b[32m     69\u001b[39m plt.xlabel(\u001b[33m'\u001b[39m\u001b[33mDate\u001b[39m\u001b[33m'\u001b[39m, fontsize=\u001b[32m12\u001b[39m)\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Kifiya AI Master Training Program 5 6 &7\\week-11\\Time-Series-Forecasting-Portfolio-Optimization\\.desvenv\\Lib\\site-packages\\pandas\\core\\frame.py:4107\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n",
      "\u001b[32m   4105\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n",
      "\u001b[32m   4106\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n",
      "\u001b[32m-> \u001b[39m\u001b[32m4107\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[32m   4108\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n",
      "\u001b[32m   4109\u001b[39m     indexer = [indexer]\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Kifiya AI Master Training Program 5 6 &7\\week-11\\Time-Series-Forecasting-Portfolio-Optimization\\.desvenv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3819\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n",
      "\u001b[32m   3814\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n",
      "\u001b[32m   3815\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n",
      "\u001b[32m   3816\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n",
      "\u001b[32m   3817\u001b[39m     ):\n",
      "\u001b[32m   3818\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n",
      "\u001b[32m-> \u001b[39m\u001b[32m3819\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n",
      "\u001b[32m   3820\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n",
      "\u001b[32m   3821\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n",
      "\u001b[32m   3822\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n",
      "\u001b[32m   3823\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n",
      "\u001b[32m   3824\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\n",
      "\u001b[31mKeyError\u001b[39m: 'TSLA'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1400x700 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#\n",
    "# Task 1: Data Preprocessing, EDA, and Risk Analysis\n",
    "#\n",
    "# This script covers the first major task of the \"Time Series Forecasting for\n",
    "# Portfolio Management Optimization\" challenge. It performs the following steps:\n",
    "# 1.  Fetches historical financial data for TSLA, BND, and SPY using the yfinance library.\n",
    "# 2.  Cleans the data by handling missing values.\n",
    "# 3.  Conducts Exploratory Data Analysis (EDA) to visualize trends and volatility.\n",
    "# 4.  Performs statistical tests for stationarity (Augmented Dickey-Fuller).\n",
    "# 5.  Calculates key risk metrics: Value at Risk (VaR) and the Sharpe Ratio.\n",
    "#\n",
    "\n",
    "# --- 0. Import Necessary Libraries ---\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "# --- 1. Data Extraction ---\n",
    "# Define the tickers and the date range for the data extraction.\n",
    "tickers = ['TSLA', 'BND', 'SPY']\n",
    "start_date = '2015-07-01'\n",
    "end_date = '2025-07-31'\n",
    "\n",
    "print(f\"Fetching data for {', '.join(tickers)} from {start_date} to {end_date}...\")\n",
    "# Download historical data from Yahoo Finance.\n",
    "# We use 'Adj Close' as it accounts for dividends and stock splits.\n",
    "data = yf.download(tickers, start=start_date, end=end_date)['Adj Close']\n",
    "print(\"Data fetching complete.\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "\n",
    "# --- 2. Data Cleaning and Understanding ---\n",
    "print(\"--- Data Cleaning and Understanding ---\")\n",
    "# Display the first few rows of the dataset\n",
    "print(\"First 5 rows of the data:\")\n",
    "print(data.head())\n",
    "print(\"\\n\")\n",
    "\n",
    "# Check basic statistics to understand the distribution of the data.\n",
    "print(\"Basic statistics of the data:\")\n",
    "print(data.describe())\n",
    "print(\"\\n\")\n",
    "\n",
    "# Check for missing values.\n",
    "print(\"Missing values in each column:\")\n",
    "print(data.isnull().sum())\n",
    "print(\"\\n\")\n",
    "\n",
    "# Handle missing values using forward fill, which is suitable for time series data.\n",
    "data.fillna(method='ffill', inplace=True)\n",
    "print(\"Missing values after forward fill:\")\n",
    "print(data.isnull().sum())\n",
    "print(\"-\" * 50)\n",
    "\n",
    "\n",
    "# --- 3. Exploratory Data Analysis (EDA) ---\n",
    "print(\"--- Performing Exploratory Data Analysis ---\")\n",
    "# Set plot style\n",
    "sns.set(style='whitegrid')\n",
    "\n",
    "# Visualize the closing prices over time\n",
    "plt.figure(figsize=(14, 7))\n",
    "for ticker in tickers:\n",
    "    plt.plot(data.index, data[ticker], label=ticker)\n",
    "plt.title('Adjusted Closing Prices (2015-2025)', fontsize=16)\n",
    "plt.xlabel('Date', fontsize=12)\n",
    "plt.ylabel('Adjusted Close Price (USD)', fontsize=12)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Calculate and plot the daily percentage change (daily returns)\n",
    "daily_returns = data.pct_change().dropna()\n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "for ticker in tickers:\n",
    "    plt.plot(daily_returns.index, daily_returns[ticker], label=ticker, alpha=0.7)\n",
    "plt.title('Daily Returns (Volatility)', fontsize=16)\n",
    "plt.xlabel('Date', fontsize=12)\n",
    "plt.ylabel('Percentage Change', fontsize=12)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Analyze volatility by calculating and plotting rolling means and standard deviations for TSLA\n",
    "rolling_window = 30\n",
    "tsla_rolling_mean = data['TSLA'].rolling(window=rolling_window).mean()\n",
    "tsla_rolling_std = data['TSLA'].rolling(window=rolling_window).std()\n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(data.index, data['TSLA'], label='TSLA Adj Close')\n",
    "plt.plot(tsla_rolling_mean.index, tsla_rolling_mean, label=f'{rolling_window}-Day Rolling Mean', color='orange')\n",
    "plt.plot(tsla_rolling_std.index, tsla_rolling_std, label=f'{rolling_window}-Day Rolling Std Dev', color='red')\n",
    "plt.title('TSLA Price with Rolling Mean and Standard Deviation', fontsize=16)\n",
    "plt.xlabel('Date', fontsize=12)\n",
    "plt.ylabel('Price (USD)', fontsize=12)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "print(\"EDA plots have been generated.\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "\n",
    "# --- 4. Seasonality and Trends (Stationarity Test) ---\n",
    "print(\"--- Performing Stationarity Tests (Augmented Dickey-Fuller) ---\")\n",
    "\n",
    "# Function to perform and interpret the ADF test\n",
    "def adf_test(series, name=''):\n",
    "    \"\"\"\n",
    "    Performs the Augmented Dickey-Fuller test for stationarity.\n",
    "    \"\"\"\n",
    "    print(f'ADF Test for: {name}')\n",
    "    result = adfuller(series.dropna())\n",
    "    print(f'ADF Statistic: {result[0]}')\n",
    "    print(f'p-value: {result[1]}')\n",
    "    print('Critical Values:')\n",
    "    for key, value in result[4].items():\n",
    "        print(f'\\t{key}: {value}')\n",
    "\n",
    "    if result[1] <= 0.05:\n",
    "        print(\"Conclusion: The series is likely stationary (reject the null hypothesis).\\n\")\n",
    "    else:\n",
    "        print(\"Conclusion: The series is likely non-stationary (fail to reject the null hypothesis).\\n\")\n",
    "\n",
    "# Perform ADF test on the closing prices (expected to be non-stationary)\n",
    "adf_test(data['TSLA'], 'TSLA Adjusted Close Price')\n",
    "\n",
    "# Perform ADF test on the daily returns (expected to be stationary)\n",
    "adf_test(daily_returns['TSLA'], 'TSLA Daily Returns')\n",
    "print(\"-\" * 50)\n",
    "\n",
    "\n",
    "# --- 5. Risk Metrics Calculation ---\n",
    "print(\"--- Calculating Foundational Risk Metrics for TSLA ---\")\n",
    "\n",
    "# Value at Risk (VaR) - 95% confidence\n",
    "# VaR at 95% confidence level means that 95% of the time, we expect the loss to be less than this value.\n",
    "confidence_level = 0.95\n",
    "var_95 = daily_returns['TSLA'].quantile(1 - confidence_level)\n",
    "print(f\"Value at Risk (VaR) at 95% confidence: {var_95:.2%}\")\n",
    "print(f\"This means that on any given day, there is a 5% chance that TSLA's stock will drop by {var_95:.2%} or more.\")\n",
    "print(\"\\n\")\n",
    "\n",
    "# Sharpe Ratio\n",
    "# The Sharpe ratio measures the performance of an investment compared to a risk-free asset, after adjusting for its risk.\n",
    "# Assuming a risk-free rate of 0 for simplicity.\n",
    "mean_return = daily_returns['TSLA'].mean()\n",
    "std_dev = daily_returns['TSLA'].std()\n",
    "# Annualize the Sharpe Ratio (assuming 252 trading days in a year)\n",
    "sharpe_ratio = (mean_return / std_dev) * np.sqrt(252)\n",
    "print(f\"Annualized Sharpe Ratio for TSLA: {sharpe_ratio:.2f}\")\n",
    "print(\"A higher Sharpe Ratio generally indicates better risk-adjusted return.\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "print(\"Task 1 script finished.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45039cb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_21968\\716076896.py:30: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(tickers, start=start_date, end=end_date)['Adj Close']\n",
      "[*********************100%***********************]  3 of 3 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for TSLA, BND, SPY from 2015-07-01 to 2025-07-31...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Adj Close'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Kifiya AI Master Training Program 5 6 &7\\week-11\\Time-Series-Forecasting-Portfolio-Optimization\\.desvenv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3811\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'Adj Close'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 30\u001b[39m\n\u001b[32m     27\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFetching data for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m.join(tickers)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstart_date\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mend_date\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     28\u001b[39m \u001b[38;5;66;03m# Download historical data from Yahoo Finance.\u001b[39;00m\n\u001b[32m     29\u001b[39m \u001b[38;5;66;03m# We use 'Adj Close' as it accounts for dividends and stock splits.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m data = \u001b[43myf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdownload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtickers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstart_date\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[43m=\u001b[49m\u001b[43mend_date\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mAdj Close\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mData fetching complete.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     32\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m-\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m50\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Kifiya AI Master Training Program 5 6 &7\\week-11\\Time-Series-Forecasting-Portfolio-Optimization\\.desvenv\\Lib\\site-packages\\pandas\\core\\frame.py:4106\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4104\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_single_key:\n\u001b[32m   4105\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m4106\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_getitem_multilevel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4107\u001b[39m     indexer = \u001b[38;5;28mself\u001b[39m.columns.get_loc(key)\n\u001b[32m   4108\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Kifiya AI Master Training Program 5 6 &7\\week-11\\Time-Series-Forecasting-Portfolio-Optimization\\.desvenv\\Lib\\site-packages\\pandas\\core\\frame.py:4164\u001b[39m, in \u001b[36mDataFrame._getitem_multilevel\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4162\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_getitem_multilevel\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[32m   4163\u001b[39m     \u001b[38;5;66;03m# self.columns is a MultiIndex\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m4164\u001b[39m     loc = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4165\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(loc, (\u001b[38;5;28mslice\u001b[39m, np.ndarray)):\n\u001b[32m   4166\u001b[39m         new_columns = \u001b[38;5;28mself\u001b[39m.columns[loc]\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Kifiya AI Master Training Program 5 6 &7\\week-11\\Time-Series-Forecasting-Portfolio-Optimization\\.desvenv\\Lib\\site-packages\\pandas\\core\\indexes\\multi.py:3059\u001b[39m, in \u001b[36mMultiIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3056\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m mask\n\u001b[32m   3058\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m3059\u001b[39m     loc = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_level_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   3060\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _maybe_to_slice(loc)\n\u001b[32m   3062\u001b[39m keylen = \u001b[38;5;28mlen\u001b[39m(key)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Kifiya AI Master Training Program 5 6 &7\\week-11\\Time-Series-Forecasting-Portfolio-Optimization\\.desvenv\\Lib\\site-packages\\pandas\\core\\indexes\\multi.py:3410\u001b[39m, in \u001b[36mMultiIndex._get_level_indexer\u001b[39m\u001b[34m(self, key, level, indexer)\u001b[39m\n\u001b[32m   3407\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mslice\u001b[39m(i, j, step)\n\u001b[32m   3409\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3410\u001b[39m     idx = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_loc_single_level_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlevel_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3412\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m level > \u001b[32m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lexsort_depth == \u001b[32m0\u001b[39m:\n\u001b[32m   3413\u001b[39m         \u001b[38;5;66;03m# Desired level is not sorted\u001b[39;00m\n\u001b[32m   3414\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(idx, \u001b[38;5;28mslice\u001b[39m):\n\u001b[32m   3415\u001b[39m             \u001b[38;5;66;03m# test_get_loc_partial_timestamp_multiindex\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Kifiya AI Master Training Program 5 6 &7\\week-11\\Time-Series-Forecasting-Portfolio-Optimization\\.desvenv\\Lib\\site-packages\\pandas\\core\\indexes\\multi.py:2999\u001b[39m, in \u001b[36mMultiIndex._get_loc_single_level_index\u001b[39m\u001b[34m(self, level_index, key)\u001b[39m\n\u001b[32m   2997\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m -\u001b[32m1\u001b[39m\n\u001b[32m   2998\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2999\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlevel_index\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Kifiya AI Master Training Program 5 6 &7\\week-11\\Time-Series-Forecasting-Portfolio-Optimization\\.desvenv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3819\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3814\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3815\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3816\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3817\u001b[39m     ):\n\u001b[32m   3818\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3819\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3820\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3821\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3822\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3823\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3824\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'Adj Close'"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Task 1: Data Preprocessing, EDA, and Risk Analysis\n",
    "#\n",
    "# This script covers the first major task of the \"Time Series Forecasting for\n",
    "# Portfolio Management Optimization\" challenge. It performs the following steps:\n",
    "# 1.  Fetches historical financial data for TSLA, BND, and SPY using the yfinance library.\n",
    "# 2.  Cleans the data by handling missing values.\n",
    "# 3.  Conducts Exploratory Data Analysis (EDA) to visualize trends and volatility.\n",
    "# 4.  Performs statistical tests for stationarity (Augmented Dickey-Fuller).\n",
    "# 5.  Calculates key risk metrics: Value at Risk (VaR) and the Sharpe Ratio.\n",
    "#\n",
    "\n",
    "# --- 0. Import Necessary Libraries ---\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "# --- 1. Data Extraction ---\n",
    "# Define the tickers and the date range for the data extraction.\n",
    "tickers = ['TSLA', 'BND', 'SPY']\n",
    "start_date = '2015-07-01'\n",
    "end_date = '2025-07-31'\n",
    "\n",
    "print(f\"Fetching data for {', '.join(tickers)} from {start_date} to {end_date}...\")\n",
    "# Download historical data from Yahoo Finance.\n",
    "# We use 'Adj Close' as it accounts for dividends and stock splits.\n",
    "data = yf.download(tickers, start=start_date, end=end_date)['Adj Close']\n",
    "print(\"Data fetching complete.\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "\n",
    "# --- 2. Data Cleaning and Understanding ---\n",
    "print(\"--- Data Cleaning and Understanding ---\")\n",
    "# Display the first few rows of the dataset\n",
    "print(\"First 5 rows of the data:\")\n",
    "print(data.head())\n",
    "print(\"\\n\")\n",
    "\n",
    "# Check basic statistics to understand the distribution of the data.\n",
    "print(\"Basic statistics of the data:\")\n",
    "print(data.describe())\n",
    "print(\"\\n\")\n",
    "\n",
    "# Check for missing values.\n",
    "print(\"Missing values in each column:\")\n",
    "print(data.isnull().sum())\n",
    "print(\"\\n\")\n",
    "\n",
    "# Handle missing values using forward fill, which is suitable for time series data.\n",
    "data.fillna(method='ffill', inplace=True)\n",
    "print(\"Missing values after forward fill:\")\n",
    "print(data.isnull().sum())\n",
    "print(\"-\" * 50)\n",
    "\n",
    "\n",
    "# --- 3. Exploratory Data Analysis (EDA) ---\n",
    "print(\"--- Performing Exploratory Data Analysis ---\")\n",
    "# Set plot style\n",
    "sns.set(style='whitegrid')\n",
    "\n",
    "# Visualize the closing prices over time\n",
    "plt.figure(figsize=(14, 7))\n",
    "for ticker in tickers:\n",
    "    plt.plot(data.index, data[ticker], label=ticker)\n",
    "plt.title('Adjusted Closing Prices (2015-2025)', fontsize=16)\n",
    "plt.xlabel('Date', fontsize=12)\n",
    "plt.ylabel('Adjusted Close Price (USD)', fontsize=12)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Calculate and plot the daily percentage change (daily returns)\n",
    "daily_returns = data.pct_change().dropna()\n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "for ticker in tickers:\n",
    "    plt.plot(daily_returns.index, daily_returns[ticker], label=ticker, alpha=0.7)\n",
    "plt.title('Daily Returns (Volatility)', fontsize=16)\n",
    "plt.xlabel('Date', fontsize=12)\n",
    "plt.ylabel('Percentage Change', fontsize=12)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Analyze volatility by calculating and plotting rolling means and standard deviations for TSLA\n",
    "rolling_window = 30\n",
    "tsla_rolling_mean = data['TSLA'].rolling(window=rolling_window).mean()\n",
    "tsla_rolling_std = data['TSLA'].rolling(window=rolling_window).std()\n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(data.index, data['TSLA'], label='TSLA Adj Close')\n",
    "plt.plot(tsla_rolling_mean.index, tsla_rolling_mean, label=f'{rolling_window}-Day Rolling Mean', color='orange')\n",
    "plt.plot(tsla_rolling_std.index, tsla_rolling_std, label=f'{rolling_window}-Day Rolling Std Dev', color='red')\n",
    "plt.title('TSLA Price with Rolling Mean and Standard Deviation', fontsize=16)\n",
    "plt.xlabel('Date', fontsize=12)\n",
    "plt.ylabel('Price (USD)', fontsize=12)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "print(\"EDA plots have been generated.\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "\n",
    "# --- 4. Seasonality and Trends (Stationarity Test) ---\n",
    "print(\"--- Performing Stationarity Tests (Augmented Dickey-Fuller) ---\")\n",
    "\n",
    "# Function to perform and interpret the ADF test\n",
    "def adf_test(series, name=''):\n",
    "    \"\"\"\n",
    "    Performs the Augmented Dickey-Fuller test for stationarity.\n",
    "    \"\"\"\n",
    "    print(f'ADF Test for: {name}')\n",
    "    result = adfuller(series.dropna())\n",
    "    print(f'ADF Statistic: {result[0]}')\n",
    "    print(f'p-value: {result[1]}')\n",
    "    print('Critical Values:')\n",
    "    for key, value in result[4].items():\n",
    "        print(f'\\t{key}: {value}')\n",
    "\n",
    "    if result[1] <= 0.05:\n",
    "        print(\"Conclusion: The series is likely stationary (reject the null hypothesis).\\n\")\n",
    "    else:\n",
    "        print(\"Conclusion: The series is likely non-stationary (fail to reject the null hypothesis).\\n\")\n",
    "\n",
    "# Perform ADF test on the closing prices (expected to be non-stationary)\n",
    "adf_test(data['TSLA'], 'TSLA Adjusted Close Price')\n",
    "\n",
    "# Perform ADF test on the daily returns (expected to be stationary)\n",
    "adf_test(daily_returns['TSLA'], 'TSLA Daily Returns')\n",
    "print(\"-\" * 50)\n",
    "\n",
    "\n",
    "# --- 5. Risk Metrics Calculation ---\n",
    "print(\"--- Calculating Foundational Risk Metrics for TSLA ---\")\n",
    "\n",
    "# Value at Risk (VaR) - 95% confidence\n",
    "# VaR at 95% confidence level means that 95% of the time, we expect the loss to be less than this value.\n",
    "confidence_level = 0.95\n",
    "var_95 = daily_returns['TSLA'].quantile(1 - confidence_level)\n",
    "print(f\"Value at Risk (VaR) at 95% confidence: {var_95:.2%}\")\n",
    "print(f\"This means that on any given day, there is a 5% chance that TSLA's stock will drop by {var_95:.2%} or more.\")\n",
    "print(\"\\n\")\n",
    "\n",
    "# Sharpe Ratio\n",
    "# The Sharpe ratio measures the performance of an investment compared to a risk-free asset, after adjusting for its risk.\n",
    "# Assuming a risk-free rate of 0 for simplicity.\n",
    "mean_return = daily_returns['TSLA'].mean()\n",
    "std_dev = daily_returns['TSLA'].std()\n",
    "# Annualize the Sharpe Ratio (assuming 252 trading days in a year)\n",
    "sharpe_ratio = (mean_return / std_dev) * np.sqrt(252)\n",
    "print(f\"Annualized Sharpe Ratio for TSLA: {sharpe_ratio:.2f}\")\n",
    "print(\"A higher Sharpe Ratio generally indicates better risk-adjusted return.\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "print(\"Task 1 script finished.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5022cfa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading TSLA...\n",
      "Error downloading TSLA: 'Adj Close'\n",
      "Downloading BND...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_21968\\3939131598.py:11: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  ticker_data = yf.download(ticker, start=start_date, end=end_date, progress=False)\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_21968\\3939131598.py:11: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  ticker_data = yf.download(ticker, start=start_date, end=end_date, progress=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error downloading BND: 'Adj Close'\n",
      "Downloading SPY...\n",
      "Error downloading SPY: 'Adj Close'\n",
      "No data downloaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_21968\\3939131598.py:11: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  ticker_data = yf.download(ticker, start=start_date, end=end_date, progress=False)\n"
     ]
    }
   ],
   "source": [
    "# Fixed data extraction\n",
    "tickers = ['TSLA', 'BND', 'SPY']\n",
    "start_date = '2015-07-01'\n",
    "end_date = '2025-07-31'\n",
    "\n",
    "# Download each ticker individually\n",
    "data_dict = {}\n",
    "for ticker in tickers:\n",
    "    try:\n",
    "        print(f\"Downloading {ticker}...\")\n",
    "        ticker_data = yf.download(ticker, start=start_date, end=end_date, progress=False)\n",
    "        if not ticker_data.empty:\n",
    "            data_dict[ticker] = ticker_data['Adj Close']\n",
    "            print(f\"Successfully downloaded {ticker}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading {ticker}: {e}\")\n",
    "\n",
    "# Combine successful downloads\n",
    "if data_dict:\n",
    "    data = pd.DataFrame(data_dict)\n",
    "    print(f\"Available columns: {list(data.columns)}\")\n",
    "else:\n",
    "    print(\"No data downloaded\")\n",
    "    data = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad362f7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_21968\\4175590635.py:2: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download('TSLA', start='2020-01-01', end='2024-12-31')['Adj Close']\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Adj Close'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Kifiya AI Master Training Program 5 6 &7\\week-11\\Time-Series-Forecasting-Portfolio-Optimization\\.desvenv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3811\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'Adj Close'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Try with just TSLA first\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m data = \u001b[43myf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdownload\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mTSLA\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m2020-01-01\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m2024-12-31\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mAdj Close\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Kifiya AI Master Training Program 5 6 &7\\week-11\\Time-Series-Forecasting-Portfolio-Optimization\\.desvenv\\Lib\\site-packages\\pandas\\core\\frame.py:4106\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4104\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_single_key:\n\u001b[32m   4105\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m4106\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_getitem_multilevel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4107\u001b[39m     indexer = \u001b[38;5;28mself\u001b[39m.columns.get_loc(key)\n\u001b[32m   4108\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Kifiya AI Master Training Program 5 6 &7\\week-11\\Time-Series-Forecasting-Portfolio-Optimization\\.desvenv\\Lib\\site-packages\\pandas\\core\\frame.py:4164\u001b[39m, in \u001b[36mDataFrame._getitem_multilevel\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4162\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_getitem_multilevel\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[32m   4163\u001b[39m     \u001b[38;5;66;03m# self.columns is a MultiIndex\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m4164\u001b[39m     loc = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4165\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(loc, (\u001b[38;5;28mslice\u001b[39m, np.ndarray)):\n\u001b[32m   4166\u001b[39m         new_columns = \u001b[38;5;28mself\u001b[39m.columns[loc]\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Kifiya AI Master Training Program 5 6 &7\\week-11\\Time-Series-Forecasting-Portfolio-Optimization\\.desvenv\\Lib\\site-packages\\pandas\\core\\indexes\\multi.py:3059\u001b[39m, in \u001b[36mMultiIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3056\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m mask\n\u001b[32m   3058\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m3059\u001b[39m     loc = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_level_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   3060\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _maybe_to_slice(loc)\n\u001b[32m   3062\u001b[39m keylen = \u001b[38;5;28mlen\u001b[39m(key)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Kifiya AI Master Training Program 5 6 &7\\week-11\\Time-Series-Forecasting-Portfolio-Optimization\\.desvenv\\Lib\\site-packages\\pandas\\core\\indexes\\multi.py:3410\u001b[39m, in \u001b[36mMultiIndex._get_level_indexer\u001b[39m\u001b[34m(self, key, level, indexer)\u001b[39m\n\u001b[32m   3407\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mslice\u001b[39m(i, j, step)\n\u001b[32m   3409\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3410\u001b[39m     idx = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_loc_single_level_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlevel_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3412\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m level > \u001b[32m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lexsort_depth == \u001b[32m0\u001b[39m:\n\u001b[32m   3413\u001b[39m         \u001b[38;5;66;03m# Desired level is not sorted\u001b[39;00m\n\u001b[32m   3414\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(idx, \u001b[38;5;28mslice\u001b[39m):\n\u001b[32m   3415\u001b[39m             \u001b[38;5;66;03m# test_get_loc_partial_timestamp_multiindex\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Kifiya AI Master Training Program 5 6 &7\\week-11\\Time-Series-Forecasting-Portfolio-Optimization\\.desvenv\\Lib\\site-packages\\pandas\\core\\indexes\\multi.py:2999\u001b[39m, in \u001b[36mMultiIndex._get_loc_single_level_index\u001b[39m\u001b[34m(self, level_index, key)\u001b[39m\n\u001b[32m   2997\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m -\u001b[32m1\u001b[39m\n\u001b[32m   2998\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2999\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlevel_index\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Kifiya AI Master Training Program 5 6 &7\\week-11\\Time-Series-Forecasting-Portfolio-Optimization\\.desvenv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3819\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3814\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3815\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3816\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3817\u001b[39m     ):\n\u001b[32m   3818\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3819\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3820\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3821\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3822\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3823\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3824\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'Adj Close'"
     ]
    }
   ],
   "source": [
    "# Try with just TSLA first\n",
    "data = yf.download('TSLA', start='2020-01-01', end='2024-12-31')['Adj Close']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".desvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
